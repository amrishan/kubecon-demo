{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and deploy on Kubeflow from Notebooks\n",
    "\n",
    "This notebook introduces you to using Kubeflow Fairing to train and deploy a model to Kubeflow on Google Kubernetes Engine (GKE), and Google Cloud ML Engine. This notebook demonstrate how to:\n",
    " \n",
    "* Train an XGBoost model in a local notebook,\n",
    "* Use Kubeflow Fairing to train an XGBoost model remotely on Kubeflow,\n",
    "  * Data is read from a PVC\n",
    "  * The append builder is used to rapidly build a docker image\n",
    "* Use Kubeflow Fairing to deploy a trained model to Kubeflow, and\n",
    "* Call the deployed endpoint for predictions.\n",
    "\n",
    "To learn more about how to run this notebook locally, see the guide to [training and deploying on GCP from a local notebook][gcp-local-notebook].\n",
    "\n",
    "[gcp-local-notebook]: https://kubeflow.org/docs/fairing/gcp-local-notebook/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up your notebook for training an XGBoost model\n",
    "\n",
    "Import the libraries required to train this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (0.13.2)\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: sklearn in /opt/conda/lib/python3.6/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from sklearn) (0.21.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->sklearn) (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.16.2)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.2.1)\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: fire in /opt/conda/lib/python3.6/site-packages (0.1.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from fire) (1.12.0)\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install joblib\n",
    "!pip3 install sklearn\n",
    "!pip3 install fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override fairing path; \n",
    "# do this before importing anything else\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "fairing_code = os.path.join(Path.home(), \"git_jlewi-kubecon-demo\", \"fairing\")\n",
    "\n",
    "if os.path.exists(fairing_code):    \n",
    "    logging.info(\"Adding %s to path\", fairing_code)\n",
    "    sys.path = [fairing_code] + sys.path\n",
    "    \n",
    "import fairing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fairing:include-cell\n",
    "import ames\n",
    "import argparse\n",
    "import fire\n",
    "import logging\n",
    "import nbconvert\n",
    "import os\n",
    "import joblib\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBRegressor\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports not to be included in the built docker image\n",
    "from fairing.builders import append\n",
    "from fairing.deployers import job\n",
    "import fairing_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(message)s')\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the data to pvc\n",
    "import shutil\n",
    "nfs_path = os.path.join(\"/mnt/kubeflow-gcfs/data/ames_dataset\")\n",
    "model_dir = os.path.join(\"/mnt/kubeflow-gcfs/models\")\n",
    "train_data = \"/mnt/kubeflow-gcfs/data/ames_dataset/train.csv\"\n",
    "model_file = os.path.join(model_dir, \"trained_ames_model.dat\")\n",
    "if not os.path.exists(nfs_path):\n",
    "    shutil.copytree(\"ames_dataset\", nfs_path)\n",
    "    \n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base image is built from the Dockerfile in the repo\n",
    "# Can be the same image as your notebook\n",
    "base_image = \"gcr.io/code-search-demo/kubecon-demo/notebook:v20190517-300d2f2-dirty-d1a703\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m `docker` not in system PATH.\n",
      "`docker` and `docker-credential-gcloud` need to be in the same PATH in order to work correctly together.\n",
      "gcloud's Docker credential helper can be configured but it will not work until this is corrected.\n",
      "gcloud credential helpers already registered correctly.\n",
      "Activated service account credentials for: [label-issues-0409-user@code-search-demo.iam.gserviceaccount.com]\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth configure-docker --quiet\n",
    "!gcloud auth activate-service-account --key-file=${GOOGLE_APPLICATION_CREDENTIALS} --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Train and Predict functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fairing:include-cell\n",
    "class HousingServe(object):    \n",
    "    def __init__(self, model_file=None):\n",
    "        self.n_estimators = 50\n",
    "        self.learning_rate = 0.1\n",
    "        if not model_file:\n",
    "            print(\"model_file not supplied; checking environment variable\")\n",
    "            model_file = os.getenv(\"MODEL_FILE\")\n",
    "        \n",
    "        self.model_file = model_file\n",
    "        print(\"model_file={0}\".format(self.model_file))\n",
    "        \n",
    "        self.model = None\n",
    "                \n",
    "\n",
    "    def train(self, train_input, model_file):\n",
    "        (train_X, train_y), (test_X, test_y) = ames.read_input(train_input)\n",
    "        model = ames.train_model(train_X,\n",
    "                                 train_y,\n",
    "                                 test_X,\n",
    "                                 test_y,\n",
    "                                 self.n_estimators,\n",
    "                                 self.learning_rate)\n",
    "\n",
    "        ames.eval_model(model, test_X, test_y)\n",
    "        ames.save_model(model, model_file)\n",
    "\n",
    "    def predict(self, X, feature_names):\n",
    "        \"\"\"Predict using the model for given ndarray.\"\"\"\n",
    "        if not self.model:\n",
    "            print(\"Loading model {0}\".format(self.model_file))\n",
    "            self.model = joblib.load(self.model_file)\n",
    "        # Do any preprocessing\n",
    "        prediction = self.model.predict(data=X)\n",
    "        # Do any postprocessing\n",
    "        return [[prediction.item(0), prediction.item(0)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your Model Locally\n",
    "\n",
    "* Train your model locally inside your notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_file not supplied; checking environment variable\n",
      "model_file=None\n",
      "[0]\tvalidation_0-rmse:177514\n",
      "Will train until validation_0-rmse hasn't improved in 40 rounds.\n",
      "[1]\tvalidation_0-rmse:161858\n",
      "[2]\tvalidation_0-rmse:147237\n",
      "[3]\tvalidation_0-rmse:134132\n",
      "[4]\tvalidation_0-rmse:122224\n",
      "[5]\tvalidation_0-rmse:111538\n",
      "[6]\tvalidation_0-rmse:102142\n",
      "[7]\tvalidation_0-rmse:93392.3\n",
      "[8]\tvalidation_0-rmse:85824.6\n",
      "[9]\tvalidation_0-rmse:79667.6\n",
      "[10]\tvalidation_0-rmse:73463.4\n",
      "[11]\tvalidation_0-rmse:68059.4\n",
      "[12]\tvalidation_0-rmse:63350.5\n",
      "[13]\tvalidation_0-rmse:59732.1\n",
      "[14]\tvalidation_0-rmse:56260.7\n",
      "[15]\tvalidation_0-rmse:53392.6\n",
      "[16]\tvalidation_0-rmse:50770.8\n",
      "[17]\tvalidation_0-rmse:48107.8\n",
      "[18]\tvalidation_0-rmse:45923.9\n",
      "[19]\tvalidation_0-rmse:44154.2\n",
      "[20]\tvalidation_0-rmse:42488.1\n",
      "[21]\tvalidation_0-rmse:41263.3\n",
      "[22]\tvalidation_0-rmse:40212.8\n",
      "[23]\tvalidation_0-rmse:39089.1\n",
      "[24]\tvalidation_0-rmse:37691.1\n",
      "[25]\tvalidation_0-rmse:36875.2\n",
      "[26]\tvalidation_0-rmse:36276.2\n",
      "[27]\tvalidation_0-rmse:35444.1\n",
      "[28]\tvalidation_0-rmse:34831.5\n",
      "[29]\tvalidation_0-rmse:34205.4\n",
      "[30]\tvalidation_0-rmse:33831.9\n",
      "[31]\tvalidation_0-rmse:33183.6\n",
      "[32]\tvalidation_0-rmse:33019.4\n",
      "[33]\tvalidation_0-rmse:32680\n",
      "[34]\tvalidation_0-rmse:32438.5\n",
      "[35]\tvalidation_0-rmse:32130.4\n",
      "[36]\tvalidation_0-rmse:31644.2\n",
      "[37]\tvalidation_0-rmse:31248.9\n",
      "[38]\tvalidation_0-rmse:31059.8\n",
      "[39]\tvalidation_0-rmse:30862.4\n",
      "[40]\tvalidation_0-rmse:30754\n",
      "[41]\tvalidation_0-rmse:30561.6\n",
      "[42]\tvalidation_0-rmse:30416.9\n",
      "[43]\tvalidation_0-rmse:30156.4\n",
      "[44]\tvalidation_0-rmse:29852.9\n",
      "[45]\tvalidation_0-rmse:29486.6\n",
      "[46]\tvalidation_0-rmse:29158.8\n",
      "[47]\tvalidation_0-rmse:29017\n",
      "[48]\tvalidation_0-rmse:28973.9\n",
      "[49]\tvalidation_0-rmse:28787.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Best RMSE on eval: 28787.72 with 50 rounds\n",
      "INFO:root:mean_absolute_error=18173.15\n",
      "INFO:root:Model export success: /tmp/trained_model.dat\n"
     ]
    }
   ],
   "source": [
    "HousingServe().train(train_data, model_file=\"/tmp/trained_model.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Fairing to Launch a K8s Job to train your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Kubeflow Fairing for training and predictions\n",
    "\n",
    "Import the `fairing` library and configure the environment that your training or prediction job will run in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fairing\n",
    "\n",
    "# Setting up google container repositories (GCR) for storing output containers\n",
    "# You can use any docker container registry istead of GCR\n",
    "GCP_PROJECT = fairing.cloud.gcp.guess_project_name()\n",
    "DOCKER_REGISTRY = 'gcr.io/{}/fairing-job'.format(GCP_PROJECT)\n",
    "PY_VERSION = \".\".join([str(x) for x in sys.version_info[0:3]])\n",
    "BASE_IMAGE = 'python:{}'.format(PY_VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use fairing to build the docker image\n",
    "\n",
    "* This uses the append builder to rapidly build docker images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:fairing.builders.append.append:Building image...\n",
      "INFO:root:Creating docker context: /tmp/fairing.context.tar.gz\n",
      "INFO:root:Adding files to context: [PosixPath('ames-xgboost-build-train-deploy.py'), 'ames.py']\n",
      "INFO:root:Context: /tmp/fairing.context.tar.gz, Adding /home/jovyan/git_jlewi-kubecon-demo/fairing/fairing/__init__.py at /app/fairing/__init__.py\n",
      "INFO:root:Context: /tmp/fairing.context.tar.gz, Adding /home/jovyan/git_jlewi-kubecon-demo/fairing/fairing/runtime_config.py at /app/fairing/runtime_config.py\n",
      "INFO:root:Context: /tmp/fairing.context.tar.gz, Adding ames-xgboost-build-train-deploy.py at /app/ames-xgboost-build-train-deploy.py\n",
      "INFO:root:Context: /tmp/fairing.context.tar.gz, Adding ames.py at /app/ames.py\n",
      "INFO:root:Loading Docker credentials for repository 'gcr.io/code-search-demo/kubecon-demo/notebook:v20190517-300d2f2-dirty-d1a703'\n",
      "INFO:root:Invoking 'docker-credential-gcloud' to obtain Docker credentials.\n",
      "INFO:root:Successfully obtained Docker credentials.\n",
      "WARNING:fairing.builders.append.append:Image successfully built in 1.1507265768013895s.\n",
      "WARNING:fairing.builders.append.append:Pushing image gcr.io/code-search-demo/fairing-job/fairing-job:8E56C585...\n",
      "INFO:root:Loading Docker credentials for repository 'gcr.io/code-search-demo/fairing-job/fairing-job:8E56C585'\n",
      "INFO:root:Invoking 'docker-credential-gcloud' to obtain Docker credentials.\n",
      "INFO:root:Successfully obtained Docker credentials.\n",
      "WARNING:fairing.builders.append.append:Uploading gcr.io/code-search-demo/fairing-job/fairing-job:8E56C585\n",
      "INFO:root:Layer sha256:124c757242f88002a858c23fc79f8262f9587fa30fd92507e586ad074afb42b6 exists, skipping\n",
      "INFO:root:Layer sha256:0ba512db704a2eb85f7f372d1c809d58589531e3bae794f0aaba86cee912f923 exists, skipping\n",
      "INFO:root:Layer sha256:9d668e55fac4c032da019ceef29722739258d4f6b0d198d4bbf7c640becade7d exists, skipping\n",
      "INFO:root:Layer sha256:4bfa6a63a3897359eff3ca3ee27c2e05ba76b790a07e6583714c1d324c2d4f21 exists, skipping\n",
      "INFO:root:Layer sha256:398d32b153e84fe343f0c5b07d65e89b05551aae6cb8b3a03bb2b662976eb3b8 exists, skipping\n",
      "INFO:root:Layer sha256:b893ca5fa31bb87be0d3fa3a403dac7ca12c955d6fd522fd35e3260dbd0e99da exists, skipping\n",
      "INFO:root:Layer sha256:9d866f8bde2a0d607a6d17edc0fbd5e00b58306efc2b0a57e0ba72f269e7c6be exists, skipping\n",
      "INFO:root:Layer sha256:079dd3e30fa3eed702bb20a2f725da9907e2732bdc4dfb2fb5084a3423c3f743 exists, skipping\n",
      "INFO:root:Layer sha256:bbf0f5f91e8108d9b0be1ceeb749e63788ce7394a184bc8a70d24017eca7b7ba exists, skipping\n",
      "INFO:root:Layer sha256:ecc17173ccb5b7692a6d31b0077b8e4f543fb45f8c2b5c252dcad9ad0c9be0f7 exists, skipping\n",
      "INFO:root:Layer sha256:9ffc02ce9f537ee4a21b90c09bf00776adda76ba1dc04f5c85a19970682583ce exists, skipping\n",
      "INFO:root:Layer sha256:fa3f2f277e67c5cbbf1dac21dc27111a60d3cd2ef494d94aa1515d3319f2a245 exists, skipping\n",
      "INFO:root:Layer sha256:5d8a6f34a39a1e098f09b39ee4e9d4a178fef6ec71c2046fe0b040c4667c8143 exists, skipping\n",
      "INFO:root:Layer sha256:d099b15c53311dc296426716edabe61dcc19e88009c19098b17ba965357c4391 exists, skipping\n",
      "INFO:root:Layer sha256:d13453f7d2b8d0adfd86c3989a5b695cef5afc3efaafe559643071f258c9f06d exists, skipping\n",
      "INFO:root:Layer sha256:eed14867f5ee443ad7efc89d0d4392683799a413244feec120f43074bc2d43ef exists, skipping\n",
      "INFO:root:Layer sha256:2f1ee468081da0ca09360c50281ed261d8b3fb01f664262c3f278d8619eb4e9a exists, skipping\n",
      "INFO:root:Layer sha256:5ec68ea63d1f5e1ecb14396ccaf21df99608b7935f78842221bebe1b72794ba6 exists, skipping\n",
      "INFO:root:Layer sha256:1dd2c58209ba9d247c0163e96fe560c6371f7c4e44e080e4b341d621b30939d6 exists, skipping\n",
      "INFO:root:Layer sha256:541a15d3a9d79f7d3e5e0f552f396406b3e3093247f71e0ae71dd8b7242ec428 exists, skipping\n",
      "INFO:root:Layer sha256:a5ba9de0ac70b35658f5898c27b52063a597d790308fb853021e881e04a6efb7 exists, skipping\n",
      "INFO:root:Layer sha256:afde35469481d2bc446d649a7a3d099147bbf7696b66333e76a411686b617ea1 exists, skipping\n",
      "INFO:root:Layer sha256:90a7e2cb4d7460e55f83c6e47f9f8d089895ee6e1cc51ae5c23eab3bdcb70363 exists, skipping\n",
      "INFO:root:Layer sha256:55dbf73eb7c7c005c3ccff29b62ff180e2f29245d14794dd6d5d8ad855d0ea88 exists, skipping\n",
      "INFO:root:Layer sha256:9ee379bde91a3cecfb08d4189af0a2bcecc2da1c5102e49443088ccd7bd9abfa exists, skipping\n",
      "INFO:root:Layer sha256:0ac67c4ff9e4dc3dbcc22f62af6caba6abc761f7ac5e78805ef993373b8eb9c1 pushed.\n",
      "INFO:root:Layer sha256:5933291dc5df65ee7ffe74378c5125976e020042f6739252c98f7426aa7891fe pushed.\n",
      "INFO:root:Finished upload of: gcr.io/code-search-demo/fairing-job/fairing-job:8E56C585\n",
      "WARNING:fairing.builders.append.append:Pushed image gcr.io/code-search-demo/fairing-job/fairing-job:8E56C585 in 2.9021660210564733s.\n"
     ]
    }
   ],
   "source": [
    "import fairing_util\n",
    "reload(fairing_util)\n",
    "preprocessor = fairing_util.ConvertNotebookPreprocessorWithFire(\"HousingServe\")\n",
    "\n",
    "if not preprocessor.input_files:\n",
    "    preprocessor.input_files = set()\n",
    "input_files=[\"ames.py\"]\n",
    "preprocessor.input_files =  set([os.path.normpath(f) for f in input_files])\n",
    "preprocessor.preprocess()\n",
    "builder = append.append.AppendBuilder(registry=DOCKER_REGISTRY,\n",
    "                                      base_image=base_image, preprocessor=preprocessor)\n",
    "builder.build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gcr.io/code-search-demo/fairing-job/fairing-job:8E56C585'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch the K8s Job\n",
    "\n",
    "* Use pod mutators to attach a PVC and credentials to the pod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:fairing.deployers.job.job:Training job fairing-job-hjjsj launched.\n",
      "WARNING:fairing.kubernetes.manager:Waiting for fairing-job-hjjsj-zz5s8 to start...\n",
      "WARNING:fairing.kubernetes.manager:Waiting for fairing-job-hjjsj-zz5s8 to start...\n",
      "WARNING:fairing.kubernetes.manager:Waiting for fairing-job-hjjsj-zz5s8 to start...\n",
      "INFO:fairing.kubernetes.manager:Pod started running True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_file not supplied; checking environment variable\n",
      "model_file=None\n",
      "[0]\tvalidation_0-rmse:177514\n",
      "Will train until validation_0-rmse hasn't improved in 40 rounds.\n",
      "[1]\tvalidation_0-rmse:161858\n",
      "[2]\tvalidation_0-rmse:147237\n",
      "[3]\tvalidation_0-rmse:134132\n",
      "[4]\tvalidation_0-rmse:122224\n",
      "[5]\tvalidation_0-rmse:111538\n",
      "[6]\tvalidation_0-rmse:102142\n",
      "[7]\tvalidation_0-rmse:93392.3\n",
      "[8]\tvalidation_0-rmse:85824.6\n",
      "[9]\tvalidation_0-rmse:79667.6\n",
      "[10]\tvalidation_0-rmse:73463.4\n",
      "[11]\tvalidation_0-rmse:68059.4\n",
      "[12]\tvalidation_0-rmse:63350.5\n",
      "[13]\tvalidation_0-rmse:59732.1\n",
      "[14]\tvalidation_0-rmse:56260.7\n",
      "[15]\tvalidation_0-rmse:53392.6\n",
      "[16]\tvalidation_0-rmse:50770.8\n",
      "[17]\tvalidation_0-rmse:48107.8\n",
      "[18]\tvalidation_0-rmse:45923.9\n",
      "[19]\tvalidation_0-rmse:44154.2\n",
      "[20]\tvalidation_0-rmse:42488.1\n",
      "[21]\tvalidation_0-rmse:41263.3\n",
      "[22]\tvalidation_0-rmse:40212.8\n",
      "[23]\tvalidation_0-rmse:39089.1\n",
      "[24]\tvalidation_0-rmse:37691.1\n",
      "[25]\tvalidation_0-rmse:36875.2\n",
      "[26]\tvalidation_0-rmse:36276.2\n",
      "[27]\tvalidation_0-rmse:35444.1\n",
      "[28]\tvalidation_0-rmse:34831.5\n",
      "[29]\tvalidation_0-rmse:34205.4\n",
      "[30]\tvalidation_0-rmse:33831.9\n",
      "[31]\tvalidation_0-rmse:33183.6\n",
      "[32]\tvalidation_0-rmse:33019.4\n",
      "[33]\tvalidation_0-rmse:32680\n",
      "[34]\tvalidation_0-rmse:32438.5\n",
      "[35]\tvalidation_0-rmse:32130.4\n",
      "[36]\tvalidation_0-rmse:31644.2\n",
      "[37]\tvalidation_0-rmse:31248.9\n",
      "[38]\tvalidation_0-rmse:31059.8\n",
      "[39]\tvalidation_0-rmse:30862.4\n",
      "[40]\tvalidation_0-rmse:30754\n",
      "[41]\tvalidation_0-rmse:30561.6\n",
      "[42]\tvalidation_0-rmse:30416.9\n",
      "[43]\tvalidation_0-rmse:30156.4\n",
      "[44]\tvalidation_0-rmse:29852.9\n",
      "[45]\tvalidation_0-rmse:29486.6\n",
      "[46]\tvalidation_0-rmse:29158.8\n",
      "[47]\tvalidation_0-rmse:29017\n",
      "[48]\tvalidation_0-rmse:28973.9\n",
      "[49]\tvalidation_0-rmse:28787.7\n",
      "Best RMSE on eval: 28787.72 with 50 rounds\n",
      "mean_absolute_error=18173.15\n",
      "Model export success: /mnt/kubeflow-gcfs/models/trained_ames_model.dat\n"
     ]
    }
   ],
   "source": [
    "import fairing_util\n",
    "reload(fairing_util)\n",
    "\n",
    "pod_spec = builder.generate_pod_spec()\n",
    "pvc_mutator = fairing_util.add_pvc_mutator(\"kubeflow-gcfs\", \"/mnt/kubeflow-gcfs\")\n",
    "deployer = job.job.Job(namespace=\"kubeflow\", \n",
    "                       cleanup=False,\n",
    "                       pod_spec_mutators=[\n",
    "                       fairing.cloud.gcp.add_gcp_credentials_if_exists, pvc_mutator])\n",
    "\n",
    "# Add command line arguments\n",
    "pod_spec.containers[0].command.extend([\"train\", train_data, model_file])\n",
    "result = deployer.deploy(pod_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: batch/v1\r\n",
      "kind: Job\r\n",
      "metadata:\r\n",
      "  creationTimestamp: \"2019-05-17T20:21:35Z\"\r\n",
      "  generateName: fairing-job-\r\n",
      "  labels:\r\n",
      "    controller-uid: 5dff10cf-78e1-11e9-8964-42010a8e00ff\r\n",
      "    fairing-deployer: job\r\n",
      "    fairing-id: 5df3e36c-78e1-11e9-b05d-0a580a000143\r\n",
      "    job-name: fairing-job-9kl8f\r\n",
      "  name: fairing-job-9kl8f\r\n",
      "  namespace: kubeflow\r\n",
      "  resourceVersion: \"13374444\"\r\n",
      "  selfLink: /apis/batch/v1/namespaces/kubeflow/jobs/fairing-job-9kl8f\r\n",
      "  uid: 5dff10cf-78e1-11e9-8964-42010a8e00ff\r\n",
      "spec:\r\n",
      "  backoffLimit: 6\r\n",
      "  completions: 1\r\n",
      "  parallelism: 1\r\n",
      "  selector:\r\n",
      "    matchLabels:\r\n",
      "      controller-uid: 5dff10cf-78e1-11e9-8964-42010a8e00ff\r\n",
      "  template:\r\n",
      "    metadata:\r\n",
      "      creationTimestamp: null\r\n",
      "      labels:\r\n",
      "        controller-uid: 5dff10cf-78e1-11e9-8964-42010a8e00ff\r\n",
      "        fairing-deployer: job\r\n",
      "        fairing-id: 5df3e36c-78e1-11e9-b05d-0a580a000143\r\n",
      "        job-name: fairing-job-9kl8f\r\n",
      "      name: fairing-deployer\r\n",
      "    spec:\r\n",
      "      containers:\r\n",
      "      - command:\r\n",
      "        - python\r\n",
      "        - /app/function_shim.py\r\n",
      "        - --serialized_fn_file\r\n",
      "        - /app/pickled_fn.p\r\n",
      "        env:\r\n",
      "        - name: FAIRING_RUNTIME\r\n",
      "          value: \"1\"\r\n",
      "        - name: GOOGLE_APPLICATION_CREDENTIALS\r\n",
      "          value: /etc/secrets/user-gcp-sa.json\r\n",
      "        image: gcr.io/code-search-demo/fairing-job/fairing-job:2721997D\r\n",
      "        imagePullPolicy: IfNotPresent\r\n",
      "        name: model\r\n",
      "        resources: {}\r\n",
      "        securityContext:\r\n",
      "          runAsUser: 0\r\n",
      "        terminationMessagePath: /dev/termination-log\r\n",
      "        terminationMessagePolicy: File\r\n",
      "        volumeMounts:\r\n",
      "        - mountPath: /etc/secrets\r\n",
      "          name: user-gcp-sa\r\n",
      "          readOnly: true\r\n",
      "        - mountPath: /mnt/kubeflow-gcfs\r\n",
      "          name: kubeflow-gcfs\r\n",
      "      dnsPolicy: ClusterFirst\r\n",
      "      restartPolicy: Never\r\n",
      "      schedulerName: default-scheduler\r\n",
      "      securityContext: {}\r\n",
      "      terminationGracePeriodSeconds: 30\r\n",
      "      volumes:\r\n",
      "      - name: user-gcp-sa\r\n",
      "        secret:\r\n",
      "          defaultMode: 420\r\n",
      "          secretName: user-gcp-sa\r\n",
      "      - name: kubeflow-gcfs\r\n",
      "        persistentVolumeClaim:\r\n",
      "          claimName: kubeflow-gcfs\r\n",
      "status:\r\n",
      "  completionTime: \"2019-05-17T20:21:41Z\"\r\n",
      "  conditions:\r\n",
      "  - lastProbeTime: \"2019-05-17T20:21:41Z\"\r\n",
      "    lastTransitionTime: \"2019-05-17T20:21:41Z\"\r\n",
      "    status: \"True\"\r\n",
      "    type: Complete\r\n",
      "  startTime: \"2019-05-17T20:21:35Z\"\r\n",
      "  succeeded: 1\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get jobs -o yaml fairing-job-9kl8f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the trained model to Kubeflow for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Cluster endpoint: http://fairing-service-6hzds.kubeflow.svc.cluster.local\n"
     ]
    }
   ],
   "source": [
    "from fairing.deployers import serving\n",
    "import fairing_util\n",
    "pod_spec = builder.generate_pod_spec()\n",
    "pvc_mutator = fairing_util.add_pvc_mutator(\"kubeflow-gcfs\", \"/mnt/kubeflow-gcfs\")\n",
    "\n",
    "module_name = os.path.splitext(preprocessor.executable.name)[0]\n",
    "deployer = serving.serving.Serving(module_name + \".HousingServe\",\n",
    "                                   service_type=\"ClusterIP\",\n",
    "                                   labels={\"app\": \"ames\"})\n",
    "    \n",
    "pvc_mutator(None, pod_spec, deployer.namespace)\n",
    "pod_spec.containers[0].env.append({\"name\": \"MODEL_FILE\", \"value\": model_file})\n",
    "url = deployer.deploy(pod_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: extensions/v1beta1\r\n",
      "kind: Deployment\r\n",
      "metadata:\r\n",
      "  annotations:\r\n",
      "    deployment.kubernetes.io/revision: \"1\"\r\n",
      "  creationTimestamp: \"2019-05-18T02:04:06Z\"\r\n",
      "  generateName: fairing-deployer-\r\n",
      "  generation: 1\r\n",
      "  labels:\r\n",
      "    app: ames\r\n",
      "    fairing-deployer: serving\r\n",
      "    fairing-id: 37632d5e-7911-11e9-8b2b-0a580a000143\r\n",
      "  name: fairing-deployer-p7m85\r\n",
      "  namespace: kubeflow\r\n",
      "  resourceVersion: \"13459603\"\r\n",
      "  selfLink: /apis/extensions/v1beta1/namespaces/kubeflow/deployments/fairing-deployer-p7m85\r\n",
      "  uid: 37658fef-7911-11e9-8964-42010a8e00ff\r\n",
      "spec:\r\n",
      "  progressDeadlineSeconds: 600\r\n",
      "  replicas: 1\r\n",
      "  revisionHistoryLimit: 10\r\n",
      "  selector:\r\n",
      "    matchLabels:\r\n",
      "      app: ames\r\n",
      "      fairing-deployer: serving\r\n",
      "      fairing-id: 37632d5e-7911-11e9-8b2b-0a580a000143\r\n",
      "  strategy:\r\n",
      "    rollingUpdate:\r\n",
      "      maxSurge: 25%\r\n",
      "      maxUnavailable: 25%\r\n",
      "    type: RollingUpdate\r\n",
      "  template:\r\n",
      "    metadata:\r\n",
      "      creationTimestamp: null\r\n",
      "      labels:\r\n",
      "        app: ames\r\n",
      "        fairing-deployer: serving\r\n",
      "        fairing-id: 37632d5e-7911-11e9-8b2b-0a580a000143\r\n",
      "      name: fairing-deployer\r\n",
      "    spec:\r\n",
      "      containers:\r\n",
      "      - command:\r\n",
      "        - seldon-core-microservice\r\n",
      "        - ames-xgboost-build-train-deploy.HousingServe\r\n",
      "        - REST\r\n",
      "        - --service-type=MODEL\r\n",
      "        - --persistence=0\r\n",
      "        env:\r\n",
      "        - name: FAIRING_RUNTIME\r\n",
      "          value: \"1\"\r\n",
      "        - name: MODEL_FILE\r\n",
      "          value: /mnt/kubeflow-gcfs/models/trained_ames_model.dat\r\n",
      "        image: gcr.io/code-search-demo/fairing-job/fairing-job:387C23BB\r\n",
      "        imagePullPolicy: IfNotPresent\r\n",
      "        name: model\r\n",
      "        resources: {}\r\n",
      "        securityContext:\r\n",
      "          runAsUser: 0\r\n",
      "        terminationMessagePath: /dev/termination-log\r\n",
      "        terminationMessagePolicy: File\r\n",
      "        volumeMounts:\r\n",
      "        - mountPath: /mnt/kubeflow-gcfs\r\n",
      "          name: kubeflow-gcfs\r\n",
      "        workingDir: /app\r\n",
      "      dnsPolicy: ClusterFirst\r\n",
      "      restartPolicy: Always\r\n",
      "      schedulerName: default-scheduler\r\n",
      "      securityContext: {}\r\n",
      "      terminationGracePeriodSeconds: 30\r\n",
      "      volumes:\r\n",
      "      - name: kubeflow-gcfs\r\n",
      "        persistentVolumeClaim:\r\n",
      "          claimName: kubeflow-gcfs\r\n",
      "status:\r\n",
      "  availableReplicas: 1\r\n",
      "  conditions:\r\n",
      "  - lastTransitionTime: \"2019-05-18T02:04:11Z\"\r\n",
      "    lastUpdateTime: \"2019-05-18T02:04:11Z\"\r\n",
      "    message: Deployment has minimum availability.\r\n",
      "    reason: MinimumReplicasAvailable\r\n",
      "    status: \"True\"\r\n",
      "    type: Available\r\n",
      "  - lastTransitionTime: \"2019-05-18T02:04:06Z\"\r\n",
      "    lastUpdateTime: \"2019-05-18T02:04:11Z\"\r\n",
      "    message: ReplicaSet \"fairing-deployer-p7m85-5dcf5fd9d6\" has successfully progressed.\r\n",
      "    reason: NewReplicaSetAvailable\r\n",
      "    status: \"True\"\r\n",
      "    type: Progressing\r\n",
      "  observedGeneration: 1\r\n",
      "  readyReplicas: 1\r\n",
      "  replicas: 1\r\n",
      "  updatedReplicas: 1\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get deploy -o yaml {deployer.deployment.metadata.name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call the prediction endpoint\n",
    "\n",
    "Create a test dataset, then call the endpoint on Kubeflow for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_y), (test_X, test_y) = ames.read_input(\"ames_dataset/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b'{\"data\":{\"names\":[\"t:0\",\"t:1\"],\"tensor\":{\"shape\":[1,2],\"values\":[165164.875,'\n",
      " b'165164.875]}},\"meta\":{}}\\n')\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "test_X\n",
    "full_url = url + \":5000/predict\"\n",
    "result = fairing_util.predict_nparray(full_url, test_X)\n",
    "pprint.pprint(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up the prediction endpoint\n",
    "\n",
    "Delete the prediction endpoint created by this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kubectl delete service -l app=ames\n",
    "# !kubectl delete deploy -l app=ames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.components as comp\n",
    "import kfp.gcp as gcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = 'Ames'\n",
    "KFP_PACKAGE = 'https://storage.googleapis.com/ml-pipeline/release/0.1.20/kfp.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the SDK\n",
    "!pip3 install $KFP_PACKAGE --upgrade\n",
    "!pip3 install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the pipeline\n",
    "Pipeline function has to be decorated with the `@dsl.pipeline` decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class ContainerOp in module kfp.dsl._container_op:\n",
      "\n",
      "class ContainerOp(BaseOp)\n",
      " |  Represents an op implemented by a container image.\n",
      " |  \n",
      " |  Example\n",
      " |  \n",
      " |      from kfp import dsl\n",
      " |      from kubernetes.client.models import V1EnvVar\n",
      " |  \n",
      " |  \n",
      " |      @dsl.pipeline(\n",
      " |          name='foo',\n",
      " |          description='hello world')\n",
      " |      def foo_pipeline(tag: str, pull_image_policy: str):\n",
      " |  \n",
      " |          # any attributes can be parameterized (both serialized string or actual PipelineParam)\n",
      " |          op = dsl.ContainerOp(name='foo', \n",
      " |                              image='busybox:%s' % tag,\n",
      " |                              # pass in sidecars list\n",
      " |                              sidecars=[dsl.Sidecar('print', 'busybox:latest', command='echo \"hello\"')],\n",
      " |                              # pass in k8s container kwargs\n",
      " |                              container_kwargs={'env': [V1EnvVar('foo', 'bar')]})\n",
      " |  \n",
      " |          # set `imagePullPolicy` property for `container` with `PipelineParam` \n",
      " |          op.container.set_pull_image_policy(pull_image_policy)\n",
      " |  \n",
      " |          # add sidecar with parameterized image tag\n",
      " |          # sidecar follows the argo sidecar swagger spec\n",
      " |          op.add_sidecar(dsl.Sidecar('redis', 'redis:%s' % tag).set_image_pull_policy('Always'))\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      ContainerOp\n",
      " |      BaseOp\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, name:str, image:str, command:Union[str, List[str]]=None, arguments:Union[str, List[str]]=None, sidecars:List[kfp.dsl._container_op.Sidecar]=None, container_kwargs:Dict=None, file_outputs:Dict[str, str]=None, output_artifact_paths:Dict[str, str]=None, is_exit_handler=False, pvolumes:Dict[str, kubernetes.client.models.v1_volume.V1Volume]=None)\n",
      " |      Create a new instance of ContainerOp.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: the name of the op. It does not have to be unique within a pipeline\n",
      " |            because the pipeline will generates a unique new name in case of conflicts.\n",
      " |        image: the container image name, such as 'python:3.5-jessie'\n",
      " |        command: the command to run in the container.\n",
      " |            If None, uses default CMD in defined in container.\n",
      " |        arguments: the arguments of the command. The command can include \"%s\" and supply\n",
      " |            a PipelineParam as the string replacement. For example, ('echo %s' % input_param).\n",
      " |            At container run time the argument will be 'echo param_value'.\n",
      " |        sidecars: the list of `Sidecar` objects describing the sidecar containers to deploy \n",
      " |                  together with the `main` container.\n",
      " |        container_kwargs: the dict of additional keyword arguments to pass to the\n",
      " |                          op's `Container` definition.\n",
      " |        file_outputs: Maps output labels to local file paths. At pipeline run time,\n",
      " |            the value of a PipelineParam is saved to its corresponding local file. It's\n",
      " |            one way for outside world to receive outputs of the container.\n",
      " |        output_artifact_paths: Maps output artifact labels to local artifact file paths.\n",
      " |            It has the following default artifact paths during compile time.\n",
      " |            {'mlpipeline-ui-metadata': '/mlpipeline-ui-metadata.json',\n",
      " |             'mlpipeline-metrics': '/mlpipeline-metrics.json'}\n",
      " |        is_exit_handler: Whether it is used as an exit handler.\n",
      " |        pvolumes: Dictionary for the user to match a path on the op's fs with a\n",
      " |            V1Volume or it inherited type.\n",
      " |            E.g {\"/my/path\": vol, \"/mnt\": other_op.pvolumes[\"/output\"]}.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  arguments\n",
      " |  \n",
      " |  command\n",
      " |  \n",
      " |  container\n",
      " |      `Container` object that represents the `container` property in \n",
      " |      `io.argoproj.workflow.v1alpha1.Template`. Can be used to update the\n",
      " |      container configurations. \n",
      " |      \n",
      " |      Example:\n",
      " |          import kfp.dsl as dsl\n",
      " |          from kubernetes.client.models import V1EnvVar\n",
      " |      \n",
      " |          @dsl.pipeline(name='example_pipeline')\n",
      " |          def immediate_value_pipeline():\n",
      " |              op1 = (dsl.ContainerOp(name='example', image='nginx:alpine')\n",
      " |                        .container\n",
      " |                          .add_env_variable(V1EnvVar(name='HOST', value='foo.bar'))\n",
      " |                          .add_env_variable(V1EnvVar(name='PORT', value='80'))\n",
      " |                          .parent # return the parent `ContainerOp`\n",
      " |                      )\n",
      " |  \n",
      " |  env_variables\n",
      " |  \n",
      " |  image\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseOp:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  add_node_selector_constraint(self, label_name, value)\n",
      " |      Add a constraint for nodeSelector. Each constraint is a key-value pair label. For the \n",
      " |      container to be eligible to run on a node, the node must have each of the constraints appeared\n",
      " |      as labels.\n",
      " |      \n",
      " |      Args:\n",
      " |        label_name: The name of the constraint label.\n",
      " |        value: The value of the constraint label.\n",
      " |  \n",
      " |  add_pod_annotation(self, name:str, value:str)\n",
      " |      Adds a pod's metadata annotation.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: The name of the annotation.\n",
      " |        value: The value of the annotation.\n",
      " |  \n",
      " |  add_pod_label(self, name:str, value:str)\n",
      " |      Adds a pod's metadata label.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: The name of the label.\n",
      " |        value: The value of the label.\n",
      " |  \n",
      " |  add_sidecar(self, sidecar:kfp.dsl._container_op.Sidecar)\n",
      " |      Add a sidecar to the Op.\n",
      " |      \n",
      " |      Args:\n",
      " |        sidecar: SideCar object.\n",
      " |  \n",
      " |  add_toleration(self, tolerations:kubernetes.client.models.v1_toleration.V1Toleration)\n",
      " |      Add K8s tolerations\n",
      " |      \n",
      " |      Args:\n",
      " |        volume: Kubernetes toleration\n",
      " |        For detailed spec, check toleration definition\n",
      " |        https://github.com/kubernetes-client/python/blob/master/kubernetes/client/models/v1_toleration.py\n",
      " |  \n",
      " |  add_volume(self, volume)\n",
      " |      Add K8s volume to the container\n",
      " |      \n",
      " |      Args:\n",
      " |        volume: Kubernetes volumes\n",
      " |        For detailed spec, check volume definition\n",
      " |        https://github.com/kubernetes-client/python/blob/master/kubernetes/client/models/v1_volume.py\n",
      " |  \n",
      " |  after(self, op)\n",
      " |      Specify explicit dependency on another op.\n",
      " |  \n",
      " |  apply(self, mod_func)\n",
      " |      Applies a modifier function to self. The function should return the passed object.\n",
      " |      This is needed to chain \"extention methods\" to this class.\n",
      " |      \n",
      " |      Example:\n",
      " |        from kfp.gcp import use_gcp_secret\n",
      " |        task = (\n",
      " |          train_op(...)\n",
      " |            .set_memory_request('1GB')\n",
      " |            .apply(use_gcp_secret('user-gcp-sa'))\n",
      " |            .set_memory_limit('2GB')\n",
      " |        )\n",
      " |  \n",
      " |  set_retry(self, num_retries:int)\n",
      " |      Sets the number of times the task is retried until it's declared failed.\n",
      " |      \n",
      " |      Args:\n",
      " |        num_retries: Number of times to retry on failures.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseOp:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  inputs\n",
      " |      List of PipelineParams that will be converted into input parameters\n",
      " |      (io.argoproj.workflow.v1alpha1.Inputs) for the argo workflow.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from BaseOp:\n",
      " |  \n",
      " |  attrs_with_pipelineparams = ['node_selector', 'volumes', 'pod_annotati...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(dsl.ContainerOp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:fairing.builders.append.append:Building image...\n",
      "INFO:root:Creating docker context: /tmp/fairing.context.tar.gz\n",
      "INFO:root:Adding files to context: [PosixPath('ames-xgboost-build-train-deploy.py'), PosixPath('ames-xgboost-build-train-deploy.py'), 'ames.py']\n",
      "WARNING:root:ames-xgboost-build-train-deploy.py already exists in Fairing context, skipping...\n",
      "INFO:root:Context: /tmp/fairing.context.tar.gz, Adding /home/jovyan/git_jlewi-kubecon-demo/fairing/fairing/__init__.py at /app/fairing/__init__.py\n",
      "INFO:root:Context: /tmp/fairing.context.tar.gz, Adding /home/jovyan/git_jlewi-kubecon-demo/fairing/fairing/runtime_config.py at /app/fairing/runtime_config.py\n",
      "INFO:root:Context: /tmp/fairing.context.tar.gz, Adding ames-xgboost-build-train-deploy.py at /app/ames-xgboost-build-train-deploy.py\n",
      "INFO:root:Context: /tmp/fairing.context.tar.gz, Adding ames.py at /app/ames.py\n",
      "INFO:root:Loading Docker credentials for repository 'gcr.io/code-search-demo/kubecon-demo/notebook:v20190517-300d2f2-dirty-d1a703'\n",
      "INFO:root:Invoking 'docker-credential-gcloud' to obtain Docker credentials.\n",
      "INFO:root:Successfully obtained Docker credentials.\n",
      "WARNING:fairing.builders.append.append:Image successfully built in 1.2209873641841114s.\n",
      "WARNING:fairing.builders.append.append:Pushing image gcr.io/code-search-demo/fairing-job/fairing-job:56B0CAF...\n",
      "INFO:root:Loading Docker credentials for repository 'gcr.io/code-search-demo/fairing-job/fairing-job:56B0CAF'\n",
      "INFO:root:Invoking 'docker-credential-gcloud' to obtain Docker credentials.\n",
      "INFO:root:Successfully obtained Docker credentials.\n",
      "WARNING:fairing.builders.append.append:Uploading gcr.io/code-search-demo/fairing-job/fairing-job:56B0CAF\n",
      "INFO:root:Layer sha256:124c757242f88002a858c23fc79f8262f9587fa30fd92507e586ad074afb42b6 exists, skipping\n",
      "INFO:root:Layer sha256:0ba512db704a2eb85f7f372d1c809d58589531e3bae794f0aaba86cee912f923 exists, skipping\n",
      "INFO:root:Layer sha256:9d668e55fac4c032da019ceef29722739258d4f6b0d198d4bbf7c640becade7d exists, skipping\n",
      "INFO:root:Layer sha256:bbf0f5f91e8108d9b0be1ceeb749e63788ce7394a184bc8a70d24017eca7b7ba exists, skipping\n",
      "INFO:root:Layer sha256:079dd3e30fa3eed702bb20a2f725da9907e2732bdc4dfb2fb5084a3423c3f743 exists, skipping\n",
      "INFO:root:Layer sha256:398d32b153e84fe343f0c5b07d65e89b05551aae6cb8b3a03bb2b662976eb3b8 exists, skipping\n",
      "INFO:root:Layer sha256:9d866f8bde2a0d607a6d17edc0fbd5e00b58306efc2b0a57e0ba72f269e7c6be exists, skipping\n",
      "INFO:root:Layer sha256:4bfa6a63a3897359eff3ca3ee27c2e05ba76b790a07e6583714c1d324c2d4f21 exists, skipping\n",
      "INFO:root:Layer sha256:b893ca5fa31bb87be0d3fa3a403dac7ca12c955d6fd522fd35e3260dbd0e99da exists, skipping\n",
      "INFO:root:Layer sha256:9ffc02ce9f537ee4a21b90c09bf00776adda76ba1dc04f5c85a19970682583ce exists, skipping\n",
      "INFO:root:Layer sha256:fa3f2f277e67c5cbbf1dac21dc27111a60d3cd2ef494d94aa1515d3319f2a245 exists, skipping\n",
      "INFO:root:Layer sha256:d099b15c53311dc296426716edabe61dcc19e88009c19098b17ba965357c4391 exists, skipping\n",
      "INFO:root:Layer sha256:ecc17173ccb5b7692a6d31b0077b8e4f543fb45f8c2b5c252dcad9ad0c9be0f7 exists, skipping\n",
      "INFO:root:Layer sha256:5ec68ea63d1f5e1ecb14396ccaf21df99608b7935f78842221bebe1b72794ba6 exists, skipping\n",
      "INFO:root:Layer sha256:5d8a6f34a39a1e098f09b39ee4e9d4a178fef6ec71c2046fe0b040c4667c8143 exists, skipping\n",
      "INFO:root:Layer sha256:d13453f7d2b8d0adfd86c3989a5b695cef5afc3efaafe559643071f258c9f06d exists, skipping\n",
      "INFO:root:Layer sha256:eed14867f5ee443ad7efc89d0d4392683799a413244feec120f43074bc2d43ef exists, skipping\n",
      "INFO:root:Layer sha256:541a15d3a9d79f7d3e5e0f552f396406b3e3093247f71e0ae71dd8b7242ec428 exists, skipping\n",
      "INFO:root:Layer sha256:2f1ee468081da0ca09360c50281ed261d8b3fb01f664262c3f278d8619eb4e9a exists, skipping\n",
      "INFO:root:Layer sha256:1dd2c58209ba9d247c0163e96fe560c6371f7c4e44e080e4b341d621b30939d6 exists, skipping\n",
      "INFO:root:Layer sha256:a5ba9de0ac70b35658f5898c27b52063a597d790308fb853021e881e04a6efb7 exists, skipping\n",
      "INFO:root:Layer sha256:90a7e2cb4d7460e55f83c6e47f9f8d089895ee6e1cc51ae5c23eab3bdcb70363 exists, skipping\n",
      "INFO:root:Layer sha256:55dbf73eb7c7c005c3ccff29b62ff180e2f29245d14794dd6d5d8ad855d0ea88 exists, skipping\n",
      "INFO:root:Layer sha256:afde35469481d2bc446d649a7a3d099147bbf7696b66333e76a411686b617ea1 exists, skipping\n",
      "INFO:root:Layer sha256:9ee379bde91a3cecfb08d4189af0a2bcecc2da1c5102e49443088ccd7bd9abfa exists, skipping\n",
      "INFO:root:Layer sha256:d2045e8580bbe02290ba46e005eb088e6a1fe11b1dad8742de8de61fbd0ca6e4 pushed.\n",
      "INFO:root:Layer sha256:fc4f8c5420bec2decdd7c19cc3da6a62ebd55db1698d210fea8d2fba76431651 pushed.\n",
      "INFO:root:Finished upload of: gcr.io/code-search-demo/fairing-job/fairing-job:56B0CAF\n",
      "WARNING:fairing.builders.append.append:Pushed image gcr.io/code-search-demo/fairing-job/fairing-job:56B0CAF in 2.698999013286084s.\n"
     ]
    }
   ],
   "source": [
    "builder.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.dsl as dsl\n",
    "from kubernetes import client as k8s_client\n",
    "from kfp import gcp\n",
    "@dsl.pipeline(\n",
    "   name='Training pipeline',\n",
    "   description='A pipeline that trains the model.'\n",
    ")\n",
    "def train_pipeline(\n",
    "   train_data=\"gs://code-search-demo_ames/data/ames_dataset/train.csv\",\n",
    "   model_file=\"gs://code-search-demo_ames/output/hello-world1.txt\",\n",
    "):      \n",
    "    command=[\"python\", preprocessor.executable.name, \"train\", train_data, model_file]\n",
    "    train_op = dsl.ContainerOp(\n",
    "            name=\"train\", \n",
    "            image=builder.image_tag,        \n",
    "            command=command,\n",
    "            ).apply(\n",
    "                gcp.use_gcp_secret('user-gcp-sa'),\n",
    "            )\n",
    "    train_op.container.working_dir = \"/app\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_func = train_pipeline\n",
    "pipeline_filename = pipeline_func.__name__ + '.pipeline.zip'\n",
    "import kfp.compiler as compiler\n",
    "compiler.Compiler().compile(pipeline_func, pipeline_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit the pipeline for execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"/pipeline/#/experiments/details/b96e70b2-e551-442d-9e04-ac35551cd07c\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"/pipeline/#/runs/details/8a41a978-792a-11e9-8964-42010a8e00ff\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Specify pipeline argument values\n",
    "arguments = {\"train_data\": \"gs://code-search-demo_ames/data/ames_dataset/train.csv\",\n",
    "             \"model_file\": \"gs://code-search-demo_ames/output/hello-world1.txt\"}\n",
    "\n",
    "#Get or create an experiment and submit a pipeline run\n",
    "import kfp\n",
    "client = kfp.Client()\n",
    "experiment = client.create_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "#Submit a pipeline run\n",
    "run_name = pipeline_func.__name__ + ' run'\n",
    "run_result = client.run_pipeline(experiment.id, run_name, pipeline_filename, arguments)\n",
    "\n",
    "#vvvvvvvvv This link leads to the run information page. (Note: There is a bug in JupyterLab that modifies the URL and makes the link stop working)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
